{  "metadata": {   "name": ""  },  "nbformat": 3,  "nbformat_minor": 0,  "worksheets": [   {    "cells": [     {      "cell_type": "heading",      "level": 2,      "metadata": {},      "source": [       "N-Gram Language Models, \u041a\u0430\u0448\u0438\u043d\u0441\u043a\u0430\u044f \u042f\u043d\u0430, 195"      ]     },     {      "cell_type": "heading",      "level": 3,      "metadata": {},      "source": [       "$\\color{green}{\u042f\u0437\u044b\u043a\u043e\u0432\u0430\u044f}$ $\\color{green}{\u043c\u043e\u0434\u0435\u043b\u044c:}$ "      ]     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "1) \u041e\u0442\u0432\u0435\u0447\u0430\u0435\u0442 \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441 -  \"$ \\textit{How likely is a string of English words good English?}$\"\n",       "\n",       "2) \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u0442 \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u043d\u0430 \u0441\u0442\u0440\u043e\u0447\u043a\u0430\u0445\n",       "$p(\\textit{the house is small}) > p(\\textit{small the is house}) $\n",       "\n",       "3) \u041f\u043e\u043c\u0430\u0433\u0430\u0435\u0442 \u0432\u044b\u0431\u0440\u0430\u0442\u044c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0435 \u0441\u043b\u043e\u0432\u043e $p(\\textit{I am going home}) > p(\\textit{I am going house})$"      ]     },     {      "cell_type": "heading",      "level": 3,      "metadata": {},      "source": [       "$\\color{green}{N-\u0433\u0440\u0430\u043c\u043c\u043d\u0430\u044f}$ $\\color{green}{\u044f\u0437\u044b\u043a\u043e\u0432\u0430\u044f}$ $\\color{green}{\u043c\u043e\u0434\u0435\u043b\u044c} $"      ]     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u0414\u0430\u043d\u0430 \u0441\u0442\u0440\u043e\u0447\u043a\u0430 \u0438\u0437 \u0441\u043b\u043e\u0432 $W = w_1, w_2, w_3, \\ldots , w_n$"      ]     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u041c\u044b \u0445\u043e\u0442\u0438\u043c \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441 \"\u041a\u0430\u043a\u0430\u044f \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u044d\u0442\u043e\u0439 \u0441\u0442\u0440\u043e\u0447\u043a\u0438 - $p(W)$?\""      ]     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u0414\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043f\u0435\u0440\u0435\u043f\u0438\u0448\u0435\u043c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c $p(w_1, w_2, w_3, \\ldots, w_n) = p(w_1) p(w_2|w_1) p(w_3|w_1, w_2) \\ldots p(w_n|w_1, w_2, \\ldots, w_{n\u22121})$"      ]     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u0422\u0435\u043f\u0435\u0440\u044c \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u0438\u0435, \u0447\u0442\u043e \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u0441\u043b\u043e\u0432\u0430 \u0437\u0430\u0432\u0438\u0441\u0438\u0442 \u0442\u043e\u043b\u044c\u043a\u043e \u043e\u0442 $k$ \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0438\u0445."      ]     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u0414\u043b\u044f $k=2$, \u0432\u044b\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043f\u0435\u0440\u0435\u043f\u0438\u0448\u0435\u0442\u0441\u044f, \u043a\u0430\u043a $p(w_1, w_2, w_3, \\ldots , w_n) \\approx p(w_1) p(w_2|w_1) p(w_3|w_2) \\ldots p(w_n|w_{n\u22121})$"      ]     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u0411\u0443\u0434\u0435\u043c \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u043e\u0446\u0435\u043d\u043a\u043e\u0439\n",       "$$ p(w_2|w_1) = \\frac{count(w_1, w_2)}{count(w_1)} $$"      ]     },     {      "cell_type": "heading",      "level": 3,      "metadata": {},      "source": [       "$\\color{green}{Add-One}$ $\\color{green}{Smoothing}$"      ]     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u041c\u043e\u0436\u0435\u0442 \u0442\u0430\u043a \u043e\u043a\u0430\u0437\u0430\u0442\u044c\u0441\u044f, \u0447\u0442\u043e \u0441\u043b\u043e\u0432\u043e \u0442\u0435\u0441\u0442\u0432\u043e\u043c \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0438 \u043d\u0435 \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u043b\u043e\u0441\u044c \u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439\u0441\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0435. \u0422\u043e\u0433\u0434\u0430 \u043f\u043e \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0439 \u0444\u043e\u0440\u043c\u0443\u043b\u0435 \u0435\u043c\u0443 \u0431\u0443\u0434\u0435\u0442 \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0432\u044b\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0430 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u043d\u0443\u043b\u0435\u0432\u0430\u044f. \u0427\u0442\u043e\u0431\u044b \u044d\u0442\u043e\u0433\u043e \u0438\u0437\u0431\u0435\u0436\u0438\u0442\u044c, \u043e\u0431\u044b\u0447\u043d\u043e \u043f\u0440\u0438\u043c\u0435\u043d\u044e\u0442 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0439 \u043f\u0440\u0438\u0435\u043c:\n",       "\n",       "$$ p = \\frac{c + 1}{n + v}\n",       " $$\n",       " \n",       "$c$ - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e $n$-\u0433\u0440\u0430\u043c\u043c\u044b \u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u043c\u0441\u044f \u0442\u0435\u043a\u0441\u0442\u0435\n",       "\n",       "$n$ - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e $n-1$-\u0433\u0440\u0430\u043c\u043c\u044b (\u0438\u0441\u0442\u043e\u0440\u0438\u0438)\n",       "\n",       "$v$ - \u0440\u0430\u0437\u043c\u0435\u0440 \u0430\u043b\u0444\u0430\u0432\u0438\u0442\u0430\n"      ]     },     {      "cell_type": "heading",      "level": 3,      "metadata": {},      "source": [       "$\\color{green}{\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f}$ $\\color{green}{\u0442\u0435\u043a\u0441\u0442\u0430}$"      ]     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u0418\u0434\u0435\u044f \u043f\u0440\u043e\u0441\u0442\u0430\u044f - \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 n-gram.  \u041f\u043e\u0442\u043e\u043c \u043d\u0430\u0447\u043d\u0435\u043c \u0441 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0439 $n$-\u0433\u0440\u0430\u043c\u043c\u044b \u0438 \u0431\u0443\u0434\u0435\u043c \u043f\u0440\u043e\u0434\u043e\u043b\u0436\u0430\u0442\u044c \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0442\u0435\u043a\u0441\u0442 \u0441\u043e\u0433\u043b\u0430\u0441\u043d\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044e. \n",       "\u0427\u0442\u043e\u0431\u044b \u0442\u0435\u043a\u0441\u0442 \u043f\u043e\u043b\u0443\u0447\u0430\u043b\u0441\u044f \u043f\u0440\u0430\u0432\u0434\u043e\u043f\u043e\u0434\u043e\u0431\u043d\u044b\u0439, \u043c\u044b \u0437\u0430\u0434\u0430\u0435\u043c \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0443\u044e \u0434\u043b\u0438\u043d\u0443 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u0438 \u0436\u0435\u043b\u0430\u0435\u043c\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0442\u0435\u043a\u0441\u0442\u0430. \"\u0416\u0435\u043b\u0430\u0435\u043c\u044b\u0439\" \u0442\u0430\u043a \u043a\u0430\u043a \u043c\u044b \u0435\u0433\u043e \u043c\u043e\u0436\u0435\u0442 \u0440\u0430\u0437\u0434\u0443\u0442\u044c \u0432 \u0437\u0430\u0434\u0430\u043d\u043d\u0443\u044e \u043a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u0443 \u0440\u0430\u0437, \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u0443\u043b\u0443\u0447\u0448\u0438\u0442 \u0447\u0438\u0442\u0430\u0435\u043c\u043e\u0441\u0442\u044c. \u0422\u0430\u043a \u0436\u0435 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u043c\u043e\u0436\u0435\u0442 \u043e\u043a\u0430\u043d\u0447\u0438\u0432\u0430\u0442\u044c\u0441\u044f \u043d\u0430 \u0440\u0430\u0437\u043d\u044b\u0435 \u0437\u043d\u0430\u043a\u0438 \u043f\u0440\u0435\u043f\u0438\u043d\u0430\u043d\u0438\u0439, \u043c\u044b \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e."      ]     },     {      "cell_type": "code",      "collapsed": false,      "input": [       "import doctest\n",       "import re\n",       "import random\n",       "import sys\n",       "from optparse import OptionParser\n",       "import string\n",       "from collections import defaultdict\n",       "\n",       "SEPARATOR_PARAGRAPHS = '\\n\\n'\n",       "SEPARATOR_SENTENCES = ('?', '!', '.')\n",       "RE_SEPARATOR_SENTENCES = '[' + '\\\\'.join(SEPARATOR_SENTENCES) + ']'\n",       "INTERNAL_PUNCTUATION_MARKS = (';', ':', ',')\n",       "RE_SEPARATOR_WORDS = r'\\w+|' + '|'.join(INTERNAL_PUNCTUATION_MARKS)\n",       "COEFFICIENT_EXPAND_SIZE = 1.2\n",       "END_SENTANCE_STATE = None\n",       "\n",       "\n",       "def count_distribution_size_paragraph(text):\n",       "    \"\"\" (str) -> defaultdict(int)\n",       "\n",       "    Count distribution size of paragraph.\n",       "    >>> dict(count_distribution_size_paragraph(\"A.\\\\n\\\\n U.S.A.\"))\n",       "    {1: 1, 3: 1}\n",       "    \"\"\"\n",       "\n",       "    distributionSizeParagraph = defaultdict(int)\n",       "    for paragraph in text.split(SEPARATOR_PARAGRAPHS):\n",       "        numberSentences = len(re.findall(RE_SEPARATOR_SENTENCES, paragraph))\n",       "        if numberSentences == 0:\n",       "            continue\n",       "        distributionSizeParagraph[numberSentences] += 1\n",       "    return distributionSizeParagraph\n",       "\n",       "\n",       "def count_markov_chain_edges(text, depth):\n",       "    \"\"\" (str, int) -> defaultdict(lambda: defaultdict(int))\n",       "\n",       "    Count distribution words.\n",       "    \"\"\"\n",       "    markovChainEdges = defaultdict(lambda: defaultdict(int))\n",       "\n",       "    for paragraph in text.split(SEPARATOR_PARAGRAPHS):\n",       "        sentences = re.split(RE_SEPARATOR_SENTENCES, paragraph)\n",       "        for sentance in sentences:\n",       "            words = re.findall(RE_SEPARATOR_WORDS, sentance, re.UNICODE)\n",       "            if len(words) < depth:\n",       "                continue\n",       "            previousStates = words[:depth]\n",       "            for state in words[depth:]:\n",       "                markovChainEdges[tuple(previousStates)]\n",       "                markovChainEdges[tuple(previousStates)][state] += 1\n",       "                previousStates = previousStates[1:] + [state]\n",       "            markovChainEdges[tuple(previousStates)]\n",       "            markovChainEdges[tuple(previousStates)][END_SENTANCE_STATE] += 1\n",       "    return markovChainEdges\n",       "\n",       "\n",       "def count_max_size_sentance(text):\n",       "    \"\"\" (str) -> int\n",       "\n",       "    Returns the maximum number of words in sentence in the text.\n",       "    >>> count_max_size_sentance(\"Abra.N.\\\\n\\\\n Usa uk.\")\n",       "    2\n",       "    \"\"\"\n",       "    maxSizeSentance = 0\n",       "    for paragraph in text.split(SEPARATOR_PARAGRAPHS):\n",       "        sentences = re.split(RE_SEPARATOR_SENTENCES, paragraph)\n",       "        lenSentences = [len(x.split()) for x in sentences]\n",       "        maxSizeSentance = max(maxSizeSentance, *lenSentences)\n",       "    return maxSizeSentance\n",       "\n",       "\n",       "def random_element(distribution):\n",       "    \"\"\" (dict(T)) -> T\n",       "\n",       "    Selects one random element following distribution.\n",       "    \"\"\"\n",       "    idRandomElement = random.randint(1, sum(distribution.values()))\n",       "    currentId = 0\n",       "    for key in distribution.keys():\n",       "        currentId += distribution[key]\n",       "        if currentId >= idRandomElement:\n",       "            return key\n",       "\n",       "\n",       "def generate_sentances(markovChainEdges, maxSizeSentance):\n",       "    \"\"\" (defaultdict(lambda: defaultdict(int)), int) -> (str, int)\n",       "\n",       "    Generate sentance which has words less than maxSizeSentance.\n",       "    \"\"\"\n",       "    sentance = []\n",       "    state = random.choice(markovChainEdges.keys())\n",       "    sentance = list(state)\n",       "\n",       "    while len(sentance) < maxSizeSentance:\n",       "\n",       "        nextWord = random_element(markovChainEdges[tuple(state)])\n",       "        if nextWord != END_SENTANCE_STATE:\n",       "            sentance.append(nextWord)\n",       "            state = list(state[1:]) + [nextWord]\n",       "        else:\n",       "            break\n",       "\n",       "    sentance[0] = string.capwords(sentance[0])\n",       "    separator = random.choice(SEPARATOR_SENTENCES)\n",       "    for i in range(len(sentance)):\n",       "        word = sentance[i]\n",       "        if word not in INTERNAL_PUNCTUATION_MARKS:\n",       "            sentance[i] = \" \" + word\n",       "    sentanceStr = \"\".join(sentance).strip() + separator\n",       "    return (sentanceStr, len(sentance))\n",       "\n",       "\n",       "def generate_news(maxSizeSentance, size, output, distributionSizeParagraph, markovChainEdges):\n",       "    \"\"\" (int,\n",       "        int,\n",       "        str,\n",       "        defaultdict(int),\n",       "        defaultdict(lambda: defaultdict(int))\n",       "        ) -> None\n",       "\n",       "    Generate news. Write news in file output .\n",       "    \"\"\"\n",       "    maxSizeText = COEFFICIENT_EXPAND_SIZE * size\n",       "    output = open(output, 'w')\n",       "    totalWords = 0\n",       "    while totalWords < size:\n",       "        sizeParagraph = random_element(distributionSizeParagraph)\n",       "\n",       "        for idSentance in range(sizeParagraph):\n",       "            if not totalWords < size:\n",       "                break\n",       "            limit_words = int(maxSizeText) - totalWords\n",       "\n",       "            sentance, lenSentance = generate_sentances(\n",       "                markovChainEdges, min(maxSizeSentance, limit_words)\n",       "                )\n",       "            totalWords += lenSentance\n",       "            output.write((sentance + ' ').encode('utf-8'))\n",       "        output.write(SEPARATOR_PARAGRAPHS)\n",       "    output.close()"      ],      "language": "python",      "metadata": {},      "outputs": [],      "prompt_number": 9     },     {      "cell_type": "code",      "collapsed": false,      "input": [       "def go(train_file, depth, maxSizeSentance, size, output):\n",       "    train = open(train_file, 'r')\n",       "    text = train.read().decode('utf8')\n",       "    \n",       "    distributionSizeParagraph = count_distribution_size_paragraph(text)\n",       "    markovChainEdges = count_markov_chain_edges(text, depth)\n",       "    maxSizeSentance = count_max_size_sentance(text)\n",       "    generate_news(maxSizeSentance, size, output, distributionSizeParagraph, markovChainEdges)\n",       "    !cat out.txt"      ],      "language": "python",      "metadata": {},      "outputs": [],      "prompt_number": 22     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u0414\u043b\u044f \u0440\u0435\u043d\u0435\u0433\u0430\u0446\u0438\u0438 \u0442\u0435\u043a\u0441\u0442\u043e\u0432 \u0432\u043e\u0437\u044c\u043c\u0435\u043c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0444\u0430\u0439\u043b \u0441 \u0441\u0432\u043e\u0434\u043a\u043e\u0439 \u043d\u043e\u0432\u043e\u0441\u0442\u0435\u0439 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u042d\u0442\u043e\u0442 \u0444\u0430\u0439\u043b \u0431\u044b\u043b \u0432\u044b\u043a\u0430\u0447\u0435\u043d \u043c\u043d\u043e\u0439 \u0441 \u043e\u0434\u043d\u043e\u0433\u043e \u043d\u043e\u0432\u043e\u0441\u0442\u043d\u043e\u0433\u043e \u0441\u0430\u0439\u0442\u0430."      ]     },     {      "cell_type": "code",      "collapsed": false,      "input": [       "train_file = \"train.txt\"\n",       "depth = 2\n",       "maxSizeSentance = 30\n",       "size = 100\n",       "output = \"out.txt\"\n",       "go(train_file, depth, maxSizeSentance, size, output)"      ],      "language": "python",      "metadata": {},      "outputs": [       {        "output_type": "stream",        "stream": "stdout",        "text": [         "\u0427\u0435\u043c \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0438\u0435! \r\n",         "\r\n",         "\u041d\u0430\u0441\u0442\u0440\u043e\u0435\u043d\u0430 \u043d\u0430 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043f\u0435\u0434\u043e\u0444\u0438\u043b\u043e\u0432, \u043d\u043e \u043e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0446\u0435\u043b\u044c, \u043f\u0435\u0440\u0432\u0430\u044f \u0441\u0442\u044b\u043a\u043e\u0432\u043a\u0430 \u0441 \u0431\u0435\u0441\u043f\u0438\u043b\u043e\u0442\u043d\u043e\u0439 \u0440\u0430\u043a\u0435\u0442\u043e\u0439 Agena, \u0431\u044b\u043b\u0430 \u0434\u043e\u0441\u0442\u0438\u0433\u043d\u0443\u0442\u0430, \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u0442 USA Today. \r\n",         "\r\n",         "\u0412\u0441\u044f \u0421\u043e\u043b\u043d\u0435\u0447\u043d\u0430\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0430 \u043c\u0438\u043a\u0440\u043e\u0441\u043a\u043e\u043f\u0438\u0447\u0435\u0441\u043a\u0438\u043c\u0438 \u043f\u044b\u043b\u0438\u043d\u043a\u0430\u043c\u0438 \u0438 \u0430\u0441\u0442\u0435\u0440\u043e\u0438\u0434\u0430\u043c\u0438, \u0438 \u0432 \u0441\u043e\u0432\u0435\u0442\u0441\u043a\u043e\u0435 \u0432\u0440\u0435\u043c\u044f \u0442\u0430\u043a\u0438\u0435 \u043e\u043f\u044b\u0442\u044b? \u0412\u043e\u0434\u044b \u0432\u044b\u0441\u0442\u0443\u043f\u0430\u043b\u0430 \u0434\u0430\u043b\u044c\u043d\u044f\u044f \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u0430 \u043f\u043e\u044f\u0441\u0430 \u0430\u0441\u0442\u0435\u0440\u043e\u0438\u0434\u043e\u0432, \u0432 \u044d\u0442\u043e\u0439 \u0444\u0430\u0437\u0435 \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0438\u0441\u043f\u044b\u0442\u044b\u0432\u0430\u0435\u0442 \u0442\u0430\u043a \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u043c\u0443\u044e \u0441\u043e\u043d\u043d\u0443\u044e \u0430\u043c\u043d\u0435\u0437\u0438\u044e, \u0432 \u0442\u043e\u043c \u0447\u0438\u0441\u043b\u0435 \u043f\u0440\u0435\u0434\u043d\u0430\u0437\u043d\u0430\u0447\u0435\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u043c\u0430\u0440\u043a\u0435\u0442\u0438\u043d\u0433\u043e\u0432\u044b\u043c\u0438 \u043a\u0430\u043c\u043f\u0430\u043d\u0438\u044f\u043c\u0438 \u0432 \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0441\u0435\u0442\u044f\u0445, \u043c\u043e\u0433\u0443\u0442 \u043f\u0440\u0435\u0434\u043e\u0442\u0432\u0440\u0430\u0449\u0430\u0442\u044c \u0441\u043a\u0430\u043f\u043b\u0438\u0432\u0430\u043d\u0438\u0435 \u0442\u0440\u043e\u043c\u0431\u043e\u0446\u0438\u0442\u043e\u0432, \u0447\u0442\u043e \u0432 \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u0441\u0430\u043c\u044b\u0445 \u0432\u044b\u0441\u043e\u043a\u043e\u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u044b\u0445 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043e\u0432 \u0433\u043e\u0440\u044e\u0447\u0435\u0433\u043e \u0434\u043b\u044f \u043a\u043e\u0441\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0440\u0430\u043a\u0435\u0442? \r\n",         "\r\n",         "\u041f\u043e \u0432\u0441\u0435\u0439 \u0432\u0438\u0434\u0438\u043c\u043e\u0441\u0442\u0438, \u043d\u0435\u0430\u043d\u0434\u0435\u0440\u0442\u0430\u043b\u044c\u0446\u044b \u0437\u043d\u0430\u043b\u0438 \u043e\u0431 \u044d\u0442\u043e\u043c \u0433\u043e\u0432\u043e\u0440\u0438\u043b\u043e\u0441\u044c \u0432 \u043e\u0442\u0447\u0435\u0442\u0435 \u043f\u0430\u0440\u043b\u0430\u043c\u0435\u043d\u0442\u0441\u043a\u043e\u0433\u043e \u043a\u043e\u043c\u0438\u0442\u0435\u0442\u0430 \u043f\u043e \u043a\u043e\u0441\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u043c \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u044f\u043c \u041a\u041e\u0421\u041f\u0410\u0420 \u0432 \u041b\u0435\u043d\u0438\u043d\u0433\u0440\u0430\u0434\u0435? \r\n",         "\r\n"        ]       }      ],      "prompt_number": 29     },     {      "cell_type": "code",      "collapsed": false,      "input": [       "train_file = \"train.txt\"\n",       "depth = 3\n",       "maxSizeSentance = 30\n",       "size = 100\n",       "output = \"out.txt\"\n",       "go(train_file, depth, maxSizeSentance, size, output)"      ],      "language": "python",      "metadata": {},      "outputs": [       {        "output_type": "stream",        "stream": "stdout",        "text": [         "\u0427\u0442\u043e \u0432\u0442\u043e\u0440\u0430\u044f \u0433\u0440\u0443\u043f\u043f\u0430 \u043a\u0440\u043e\u0432\u0438 \u0441\u0432\u044f\u0437\u0430\u043d\u0430 \u0441 \u043f\u043e\u0432\u044b\u0448\u0435\u043d\u043d\u044b\u043c \u0440\u0438\u0441\u043a\u043e\u043c \u0447\u0440\u0435\u0437\u043c\u0435\u0440\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0441\u0442\u0432\u0430 \u043b\u0438\u043f\u043e\u043f\u0440\u043e\u0442\u0435\u0438\u043d\u0430 \u043c\u044f\u0433\u043a\u043e\u0433\u043e \u0445\u043e\u043b\u0435\u0441\u0442\u0435\u0440\u0438\u043d\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043c\u043e\u0436\u0435\u0442 \u0437\u0430\u043a\u0443\u043f\u043e\u0440\u0438\u0432\u0430\u0442\u044c \u0430\u0440\u0442\u0435\u0440\u0438\u0438? \u041f\u0440\u043e\u0448\u043b\u0438 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0443 \u0441\u043e\u043b\u043d\u0435\u0447\u043d\u044b\u0435 \u0431\u0430\u0442\u0430\u0440\u0435\u0438 \u0438 \u0430\u043a\u043a\u0443\u043c\u0443\u043b\u044f\u0442\u043e\u0440\u044b. \u0421\u043e\u0432\u0435\u0449\u0430\u043d\u0438\u0435 \u043f\u043e \u0442\u0435\u043c\u0430\u0442\u0438\u043a\u0435 \u043a\u043e\u0441\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043e\u0442\u0440\u0430\u0441\u043b\u0438, \u0437\u0430\u043f\u0443\u0441\u043a\u0438 \u0440\u0430\u043a\u0435\u0442 \u043d\u043e\u0441\u0438\u0442\u0435\u043b\u0435\u0439 \u0442\u0438\u043f\u0430 \u041f\u0440\u043e\u0442\u043e\u043d \u041c \u0441 \u0411\u0430\u0439\u043a\u043e\u043d\u0443\u0440\u0430, 15 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 \u043f\u043b\u0430\u043d\u0438\u0440\u0443\u0435\u0442\u0441\u044f \u043e\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0438\u0442\u044c \u043c\u043e\u0440\u0441\u043a\u043e\u0439 \u0441\u0442\u0430\u0440\u0442, 30 \u0430\u0432\u0433\u0443\u0441\u0442\u0430 \u0441 \u0411\u0430\u0439\u043a\u043e\u043d\u0443\u0440\u0430? \r\n",         "\r\n",         "\u041f\u043e\u043b\u044e\u0441\u0430\u043c\u0438 \u0434\u043e\u043b\u0436\u043d\u043e \u0431\u044b\u0442\u044c \u043c\u0435\u043d\u044c\u0448\u0435 \u044d\u043a\u0432\u0430\u0442\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0434\u0438\u0430\u043c\u0435\u0442\u0440\u0430. 5 \u0441\u0435\u043a\u0443\u043d\u0434, \u0441\u043e\u043e\u0431\u0449\u0430\u0435\u0442\u0441\u044f \u043d\u0430 \u0441\u0430\u0439\u0442\u0435 \u0420\u043e\u0441\u043a\u043e\u0441\u043c\u043e\u0441\u0430. \r\n",         "\r\n",         "\u0412\u0441\u0442\u0440\u0435\u0442\u0438\u043b\u0438 \u043f\u043e \u043f\u0440\u0438\u0435\u0437\u0434\u0443 \u0434\u0435\u0442\u0438, \u041a\u043e\u043d\u043e\u043d\u0435\u043d\u043a\u043e \u043e\u0442\u0432\u0435\u0442\u0438\u043b, \u0447\u0442\u043e \u0432 \u0447\u0438\u0441\u043b\u0435 \u0442\u0435\u043c \u0432\u0441\u0442\u0440\u0435\u0447\u0438 \u0431\u0443\u0434\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043e \u0432\u0437\u0430\u0438\u043c\u043e\u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u044f\u0445 \u043e\u0431\u0449\u0435\u0441\u0442\u0432\u0430 \u0438 \u0441\u0435\u0439\u0441\u043c\u043e\u043b\u043e\u0433\u043e\u0432. \u0417\u0430\u0440\u0443\u0431\u0435\u0436\u043d\u044b\u0435 \u043f\u0440\u043e\u0432\u0430\u0439\u0434\u0435\u0440\u044b \u0443\u0441\u043b\u0443\u0433 \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u043e\u0439 \u043f\u043e\u0447\u0442\u044b, \u0442\u0430\u043a\u0438\u0435 \u043a\u0430\u043a \u0434\u043e\u0445\u043e\u0434 \u0441\u0435\u043c\u044c\u0438! \u041a\u043e\u0441\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0430\u043f\u043f\u0430\u0440\u0430\u0442\u0430 \u0432 \u043b\u044e\u0431\u043e\u0435 \u0432\u0440\u0435\u043c\u044f \u0433\u043e\u0434\u0430 \u0438 \u0441\u0443\u0442\u043e\u043a, \u0433\u043e\u0432\u043e\u0440\u0438\u0442\u0441\u044f \u0432 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0438 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438? \r\n",         "\r\n"        ]       }      ],      "prompt_number": 30     },     {      "cell_type": "markdown",      "metadata": {},      "source": [       "\u0410 \u0442\u0435\u043f\u0435\u0440\u044c \u044f \u0432\u0437\u044f\u043b\u0430 \u0431\u043e\u043b\u044c\u0448\u0443\u044e \u043a\u043d\u0438\u0433\u0443 \u043d\u0430 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435."      ]     },     {      "cell_type": "code",      "collapsed": false,      "input": [       "train_file = \"Anatole_France.txt\"\n",       "depth = 3\n",       "maxSizeSentance = 30\n",       "size = 100\n",       "output = \"out.txt\"\n",       "go(train_file, depth, maxSizeSentance, size, output)"      ],      "language": "python",      "metadata": {},      "outputs": [       {        "output_type": "stream",        "stream": "stdout",        "text": [         "Yet gone over to clericalism, or Jules Lema\u00eetre to nationalism, or Hervieu to the theatre? A friend in the country! Her, were cruel apes, there was every probability of their descendants being the same! Intelligence of the electors who had nominated him? But confesses that his own predilection was in favour of the Jewesses. My revered teacher has impressed upon me that kings would be less liable to error if they were acquainted with the history of mankind. Illusions in politics, of the heroine, a Grecian courtesan: This woman showed herself at the festival games, and did not hesitate to bring the whole weight of his influence publicly to bear when it. \r\n",         "\r\n"        ]       }      ],      "prompt_number": 25     },     {      "cell_type": "code",      "collapsed": false,      "input": [],      "language": "python",      "metadata": {},      "outputs": []     }    ],    "metadata": {}   }  ] }
